---
title: "Reproduction of Chakraborty 2021: An intracategorical analysis of COVID-19 and people with disabilities"
author: "Joseph Holler, Junyi Zhou, Peter Kedron, Drew An-Pham, Derrick Burt"
date: "`r Sys.Date()`"
output: pdf_document
editor_options: 
  markdown: 
    wrap: sentence
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../docs/report") })
---

Version 1.4 \| First Created Jul 7, 2021

# Abstract

Chakraborty (2021) investigates the relationships between COVID-19 rates and demographic characteristics of people with disabilities by county in the lower 48 states.
The aim of the study is to investigate whether people with disabilities (PwDs) face disproportionate challenges due to COVID-19.
To do so, Chakraborty examines the statistical relationship between county incidence rates of COVID-19 cases and county-level percentages of people with disabilities and different socio-demographic characteristics.
Specifically, Chakraborty tests county-level bivariate correlations between COVID-19 incidence against the percentage of disability as one hypothesis, and tests correlation between COVID-19 incidence and percentage of people with disabilities in 18 different socio-demographic categories of race, ethnicity, poverty status, age, and biological sex.
Chakraborty then re-tests for the same county-level associations while controlling for spatial dependence.
Spatial dependence is controlled by constructing generalized estimating equation (GEE) models using a combination of state and spatial clusters of COVID-19 incidence as to define the GEE clusters.
One GEE model is constructed for each of the four types of socio-demographic category: race, ethnicity, age, and biological sex.
Chakraborty (2021) finds significant positive relationships between COVID-19 rates and socially vulnerable demographic categories of race, ethnicity, poverty status, age, and biological sex.

This reproduction study is motivated by expanding the potential impact of Chakraborty's study for policy, research, and teaching purposes.
Measuring the relationship between COVID-19 incidence and socio-demographic and disability characteristics can provide important information for public health policy-making and resource allocation.
A fully reproducible study will increase the accessibility, transparency, and potential impact of Chakraborty's (2021) study by publishing a compendium complete with metadata, data, and code.
This will allow other researchers to review, extend, and modify the study and will allow students of geography and spatial epidemiology to learn from the study design and methods.

In this reproduction, we will attempt to identically reproduce all of the results from the original study.
This will include the map of county level distribution of COVID-19 incidence rates (Fig. 1), the summary statistics for disability and sociodemographic variables and bivariate correlations with county-level COVID-19 incidence rate (Table 1), and the GEE models for predicting COVID-19 county-level incidence rate (Table 2).
A successful reproduction should be able to generate identical results as published by Chakraborty (2021).

The replication study data and code will be made available in a GitHub repository to the greatest extent that licensing and file sizes permit.
The repository will be made public at [github.com/HEGSRR/RPr-Chakraborty2021]().

Chakraborty, J.
2021.
Social inequities in the distribution of COVID-19: An intra-categorical analysis of people with disabilities in the U.S.
*Disability and Health Journal* 14:1-5.
[DOI:[10.1016/j.dhjo.2020.101007](DOI:%5B10.1016/j.dhjo.2020.101007){.uri}]()

## Keywords

COVID-19; Disability; Intersectionality; Race/ethnicity; Poverty; Reproducibility

# Study design

The aim of this reproduction study is to implement the original study as closely as possible to reproduce the map of county level distribution of COVID-19 incidence rate, the summary statistics and bivariate correlation for disability characteristics and COVID-19 incidence, and the generalized estimating equations.
Our two confirmatory hypotheses are that we will be able to exactly reproduce Chakraborty's results as presented in table 1 and table 2.
Stated as null hypotheses:

> H1: There is a less than perfect match between Chakraborty's bivariate correlation coefficient for each disability/sociodemographic variable and COVID-19 incidence rate and our bivariate correlation coefficient for each disability/sociodemographic variable and COVID-19 incidence rate.

> H2: There is a less than perfect match between Chakraborty's beta coefficient for the GEE of each disability/sociodemographic variable and our beta coefficient for the GEE of each disability/sociodemographic variable.

There are multiple models being tested within each of the two hypotheses.
That is, H1 and H2 both encompass five models, including one for each dimension of socio-demographics: race, ethnicity, poverty status, age, and biological sex.

# Original study design

The original study is **observational**, with the **exploratory** objective of determining "whether COVID-19 incidence is significantly greater in counties containing higher percentages of socio-demographically disadvantaged [people with disabilities], based on their race, ethnicity, poverty status, age, and biological sex" (Chakraborty 2021).
This exploratory objective is broken down into five implicit hypotheses that each of the demographic characteristics of people with disabilities is associated with higher COVID-19 incidence rates.

The **spatial extent** of the study are the 49 contiguous states in the U.S.
The **spatial scale** of the analysis is at the county level.
Both COVID-19 incidence rates and demographic variables are all measured at the county level.
The **temporal extent** of the COVID-19 data ranges from 1/22/2020 (when John Hopkins began collecting the data) to 8/1/2020 (when the data was retrieved for the original study).
The data on disability and sociodemographic characteristics come from the U.S.
Census American Community Survey (ACS) five-year estimates for 2018 (2014-2018).

There is no **randomization** in the original study.

![](../../docs/report/workflow.jpg "Workflow diagram")

# Computational environment

The study was originally conducted using SaTScan software to implement the Kulldorff spatial scan statistic.
Other software are not specified in the publication; however data files suggest and communication with the author verifies that spatial analysis and mapping was conducted in ArcGIS, generalized estimating equation (GEE) models were calculated in SPSS, and the SaTScan software version was `9.6`.

This reproduction study uses R, including the SpatialEpi package for the Kulldorff spatial scan statistics and the geepack package for GEE models.

```{r setup, message = FALSE, include = FALSE}
# list of required packages
packages <- c(
  "tidycensus", "tidyverse", "downloader", "sf", "classInt", "readr",
  "here", "s2", "pastecs", "tmap", "SpatialEpi", "svDialogs",
  "geepack", "knitr", "kableExtra", "foreign", "broom"
)

# load and install required packages
package.check <- lapply(
  packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE, quietly = TRUE)
      library(x, character.only = TRUE)
    }
  }
)

# save the R processing environment
writeLines(
  capture.output(sessionInfo()),
  here("procedure", "environment", paste0("r-environment-", Sys.Date(), ".txt"))
)

# set up default knitr parameters
knitr::opts_chunk$set(
  echo = FALSE,
  fig.width = 8,
  fig.path = here("results", "figures")
)
```

# Data

## American Community Survey

American Community Survey (ACS) data for sociodemographic subcategories of people with disabilities can be accessed by using the `tidycensus` package to query the Census API. This requires an API key which can be acquired at [api.census.gov/data/key_signup.html](https://api.census.gov/data/key_signup.html)

```{r API-Load-ACS, message = FALSE, warning = FALSE, eval = FALSE}
# get API Key
# we could store this in the raw/private or scratch folder and load if the
# researcher has already entered it once
census_api_key(
  dlgInput(
    "Enter a Census API Key",
    Sys.getenv("CENSUS_API_KEY")
  )$res,
  overwrite = TRUE
)

# Query disability demographic data with geographic boundaries
acs <- get_acs(
  geography = "county",
  table = "S1810",
  year = 2018,
  output = "wide",
  cache_table = TRUE,
  geometry = TRUE,
  keep_geo_vars = TRUE
)

# Query poverty and disability data
acs_pov <- get_acs(
  geography = "county",
  table = "C18130",
  year = 2018,
  output = "wide",
  cache_table = TRUE
)

# Query state geographic data
state <- get_acs(
  geography = "state",
  year = 2018,
  variables = c("B01001_001"),
  geometry = TRUE,
  keep_geo_vars = TRUE
)

# Save query results
saveRDS(acs, here("data", "raw", "public", "acs.RDS"))
saveRDS(acs_pov, here("data", "raw", "public", "acs_pov.RDS"))
saveRDS(state, here("data", "raw", "public", "state.RDS"))
```

```{r load-acs}
acs <- readRDS(here("data", "raw", "public", "acs.RDS"))
acs_pov <- readRDS(here("data", "raw", "public", "acs_pov.RDS"))
state <- readRDS(here("data", "raw", "public", "state.RDS"))
```

The original study extent is the lower 48 states and Washington D.C. Therefore, Alaska, Hawai'i and Puerto Rico are removed from the data (workflow step 1).
Data on people with disabilities in poverty is derived from a different census table (C18130) than data on people with disabilities and age, race, ethnicity, age, and biological sex (S1810).
Therefore, join the poverty data to the other data using the GEOID (workflow step 3).
Also transform the ACS geographic data into Contiguous USA Albers Equal Area projection and fix geometry errors.

```{r filter-join-acs}
# Remove Alaska, Hawaii & Puerto Rico,
# transform coordinate system and fix geometries
acs <- filter(acs, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070) %>%
  st_make_valid()

# Remove Alaska, Hawaii & Puerto Rico,
state <- filter(state, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070)

# Join poverty data to disability data
acs <- left_join(acs, acs_pov, by = "GEOID")
rm(acs_pov)
```

Optionally, save the raw ACS data to `data/raw/public/acs.gpkg` for use in GIS software.

```{r save-ACS, message = F, eval = FALSE}
# Save downloaded acs data to acs.gpkg
write_sf(
  acs,
  here("data", "derived", "public", "acs.gpkg"),
  layer = "acs"
)
write_sf(
  state,
  here("data", "derived", "public", "acs.gpkg"),
  layer = "state"
)
```

Calculate independent socio-demographic variables of people with disabilities as percentages for each sub-category of disability (race, ethnicity, poverty, age, and biological sex) and remove raw census data from the data frame (workflow step 4).
Reproject the data into an Albers equal area conic projection.

```{r Preprocess-ACS}
# calculate percentages
acs_derived <- mutate(acs,
  dis_pct = S1810_C02_001E / S1810_C01_001E * 100,
  white_pct = S1810_C02_004E / S1810_C01_001E * 100,
  black_pct = S1810_C02_005E / S1810_C01_001E * 100,
  native_pct = S1810_C02_006E / S1810_C01_001E * 100,
  asian_pct = S1810_C02_007E / S1810_C01_001E * 100,
  other_pct =
    (S1810_C02_008E + S1810_C02_009E + S1810_C02_010E) / S1810_C01_001E * 100,
  non_hisp_white_pct = S1810_C02_011E / S1810_C01_001E * 100,
  hisp_pct = S1810_C02_012E / S1810_C01_001E * 100,
  non_hisp_non_white_pct =
    (S1810_C02_001E - S1810_C02_012E - S1810_C02_011E) / S1810_C01_001E * 100,
  bpov_pct = (C18130_004E + C18130_011E + C18130_018E) / C18130_001E * 100,
  apov_pct = (C18130_005E + C18130_012E + C18130_019E) / C18130_001E * 100,
  pct_5_17 = S1810_C02_014E / S1810_C01_001E * 100,
  pct_18_34 = S1810_C02_015E / S1810_C01_001E * 100,
  pct_35_64 = S1810_C02_016E / S1810_C01_001E * 100,
  pct_65_74 = S1810_C02_017E / S1810_C01_001E * 100,
  pct_75 = S1810_C02_018E / S1810_C01_001E * 100,
  male_pct = S1810_C02_002E / S1810_C01_001E * 100,
  female_pct = S1810_C02_003E / S1810_C01_001E * 100
)

# select only relevant geographic identifiers and derived percentages
acs_derived <- acs_derived %>%
  select(
    fips = GEOID,
    statefp = STATEFP,
    county = NAME.x,
    county_st = NAME,
    contains("pct")
  ) 

head(acs_derived)
```

## COVID-19 rates

Data on COVID-19 rates from the Johns Hopkins University dashboard have been provided directly with the research compendium because the data is no longer available online in the state in which it was downloaded on August 1, 2020.
The dashboard and cumulative counts of COVID-19 cases and deaths were continually updated, so an exact reproduction required communication with the original author, Jayajit Chakraborty, for assistance with provision of data from August 1, 2020.

```{r load-covid-data}
covid <- read_sf(here("data", "raw", "public", "covidcase080120.gpkg"))

# select and rename the fips code, population, cases, and x,y coordinates
covid <- select(covid,
  fips = FIPS,
  pop = POP_ESTIMA,
  cases = Confirmed,
  x = X, y = Y
)
```

Calculate the COVID incidence rate as the cases per 100,000 people (workflow step 2).
Convert the COVID data to a non-geographic data frame.

```{r covid-rate}
covid_table <- covid %>% 
  mutate(covid_rate = round(covid$cases / covid$pop * 100000, 2)) %>% 
  st_drop_geometry()

head(covid_table)
```

Join dependent COVID data to independent ACS sociodemographic data.

```{r join-covid-to-acs}
# Join COVID incidence rate data to acs data
acs_covid <- acs_derived %>%
  left_join(covid_table, by = "fips")

# move covid_rate column prior to disability percentages
acs_covid <- acs_covid %>%
  select(fips, statefp, county, county_st, covid_rate, everything())

rm(acs, acs_derived, covid)
acs_covid %>% st_drop_geometry() %>% head()
```

## Missing data

There is one county with missing disability and poverty data.
This was not mentioned in the original study or our pre-analyis plan.
However, we replace the missing data with zeros, producing results identical to Chakraborty's.

```{r missing data}
# county with missing data
filter(acs_covid, is.na(bpov_pct)) %>% st_drop_geometry()

# replace NA with 0 for missing data
acs_covid[is.na(acs_covid$bpov_pct), ]$bpov_pct <- 0
acs_covid[is.na(acs_covid$apov_pct), ]$apov_pct <- 0
```

## Map COVID-19 incidence

Map the county level distribution of COVID-19 incidence rates, comparing to Figure 1 of the original study.

```{r map-covid-rates, message = FALSE}
tm_covid_rates <- tm_shape(acs_covid) +
  tm_polygons("covid_rate",
    title = "COVID-19 Cases per 100,000 people\n(22 January 2020 to 1 August 2020)",
    style = "quantile",
    border.alpha = .2,
    lwd = 0.2,
    palette = "YlOrBr",
  ) +
  tm_shape(state) +
    tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_covid_rates
```

## Map disability rates

**Unplanned deviation for reproduction**: We also map the spatial distribution of the percent of people with any disability to improve our understanding of the geographic patterns and relationships of between the overarching independent variable (percentage of people with disability) and the dependent variable (COVID-19 incidence rate).

```{r map-disability-rates, message = FALSE}
tm_disability_rates <- tm_shape(acs_covid) +
  tm_polygons("dis_pct",
    title = "Percent of People with Disability\n(ACS 2014-2018)",
    style = "quantile",
    border.alpha = .2,
    lwd = 0.2,
    palette = "YlOrBr"
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_disability_rates
```

## Descriptive statistics

Calculate descriptive statistics for dependent COVID-19 rate and independent socio-demographic characteristics, reproducing the min, max, mean, and SD columns of original study table 1.

**Planned deviation for reanalysis**: We also calculate the Shapiro Wilk test for normality.

```{r descriptive-statistics}
acs_covid_stats <- acs_covid %>%
  st_drop_geometry() %>%
  select(covid_rate, contains("pct")) %>%
  stat.desc(norm = TRUE) %>%
  round(2) %>%
  t() %>%
  as.data.frame() %>%
  select(min, max, mean, SD = std.dev, ShapiroWilk = normtest.W, p = normtest.p)

acs_covid_stats %>% 
  kable() %>% 
  column_spec(2:6, width_min = "5em") %>% 
  column_spec(7, width_min = "2em") %>% 
  kable_styling(full_width = FALSE)
```

Compare reproduced descriptive statistics to original descriptive statistics.
Difference is calculated as 'reproduction study - original study'.
Identical results will result in zero.

```{r compare-descriptive-stats}
# load original table 1 results
table1 <- read.csv(here("data", "raw", "public", "chakraborty", "table1.csv"))

# subtract original results from reproduced results
(select(acs_covid_stats, min, max, mean, SD) -
  select(table1, min, max, mean, SD)) %>%
  kable() %>% 
  column_spec(2:5, width = "4em") %>% 
  kable_styling(full_width = FALSE)

rm(acs_covid_stats)
```

The descriptive statistics are identical, except that the original study seems to have rounded the COVID-19 statistics to zero decimal places.

# Analytical methods

## Bivariate parametric correlation analysis

Calculate Pearson's R Correlation Coefficient of each independent variable and the COVID-19 incidence rate, reproducing the Pearson's R column of original study Table 1.

```{r pearsons-correlation}
df <- sum(!is.na(acs_covid$dis_pct)) - 2

pearsons_r <- acs_covid %>%
  select(where(is.numeric)) %>%
  st_drop_geometry() %>%
  cor(method = "pearson", use = "everything") %>%
  as.data.frame() %>%
  select(r = covid_rate) %>%
  mutate(
    t = abs(r) / sqrt((1 - r^2) / (df)),
    p = pt(t, df, lower.tail = FALSE)
  ) %>%
  round(3) %>%
  rownames_to_column("variable") %>%
  filter(variable != "covid_rate")

pearsons_r %>% 
  kable() %>% 
  column_spec(2:4, width = "4em") %>% 
  kable_styling(full_width = FALSE)
```

Compare the reproduced Pearson's *r* correlation coefficients to the original study's Pearson's *r* correlation coefficients.
Stars indicates the significance level with two stars for `p < 0.01` and one star for `p < 0.05`.
Correlation difference `rp_r_diff` is calculated between the reproduction study `rp_r` and original study `or_r` as `rp_r_diff = rp_r - or_r` Direction difference `rp_dir_diff` is calculated as `(rp_r > 0) - (or_r > 0)`, giving `0` if both coefficients have the same direction, `1` if the reproduction is positive and the original is negative, and `-1` if the reproduction is negative but the original is positive.

```{r compare-pearsons-correlation}
# calculate number of significance stars at p < 0.01 and p < 0.05 levels.
pearsons_r <- mutate(pearsons_r, rp_stars = as.numeric(as.character(cut(p,
  breaks = c(-0.1, 0.01, 0.05, 1),
  labels = c(2, 1, 0)
))))

# join reproduction coefficients to original study coefficients
correlations <- table1 %>%
  filter(variable != "covid_rate") %>%
  select(variable, or_r = r, or_stars = stars) %>%
  left_join(select(pearsons_r, variable, rp_r = r, rp_stars), by = "variable")

# find difference between coefficient and stars
correlations <- correlations %>%
  bind_cols(rename_with(
    correlations[, 4:5] - correlations[, 2:3],
    ~ paste0(.x, "_diff")
  ))

# find coefficients with different directions
correlations <- correlations %>% mutate(rp_dir_diff = (rp_r > 0) - (or_r > 0))

correlations %>% kable() %>% kable_styling()
```

Reproduction correlation coefficients varied slightly from the original study coefficients by +/- 0.006.
All but one Pearson's correlation coefficient was significant to the same level, and the exception was age 18 to 34.
Counter-intuitively, the correlation coefficient was slightly closer to 0 but the *p* value was also found to be more significant, suggesting a difference in the estimation of *t* and/or *p*, or a typographical error.
All of the coefficients had the same direction.

**Unplanned Deviation for Reproduction**: 
We should expect identical results for this correlation test, so we loaded the original author's data from `Aug1GEEdata.csv` to re-test the statistic, calculated as `unplanned_r` below.

```{r original-data-pearson-correlation}
# load author-provided original data
original_gee <- read.csv(here("data", "raw", "public", "chakraborty", "Aug1GEEdata.csv"))

# calculate correlation coefficients using original data
original_gee %>%
  select(Incidence, PerDisable, starts_with("PD")) %>%
  cor(method = "pearson", use = "everything") %>%
  as.data.frame() %>%
  rownames_to_column("or_variable") %>%
  filter(or_variable != "Incidence") %>%
  select(or_variable, unplanned_r = Incidence) %>%
  bind_cols(correlations[, 1:2]) %>%
  mutate(unplanned_r = round(unplanned_r, 3), diff = unplanned_r - or_r) %>%
  select(variable, unplanned_r, or_r, diff) %>%
  kable() %>% kable_styling()
```

The author's original data produced coefficients identical to the original publication!
Is it possible that the data values are correct but have been reassigned / transposed to different counties?

*Unplanned Deviation for Reproduction*: 
Considering the precise bitwise reproduction of descriptive statistics and of correlation statistics from author-provided data, we decided to recalculate the COVID-19 incidence rate with author-provided case and population data for comparison to the author-provided incidence rate.

```{r compare-incidence-rate}
# recalculate Incidence Rate
original_gee <- original_gee %>%
  mutate(recalc_Incidence = round(Cases / Total_POP * 100000, 2))

# compare recalculation to author-provided original data and print any counties
# with inconsistent results
original_gee %>%
  filter(recalc_Incidence != Incidence) %>%
  select(COUNTY_FIPS, ST_Name, Countyname, Total_POP, Cases, Incidence, recalc_Incidence) %>%
  mutate(Incidence_diff = recalc_Incidence - Incidence) %>% 
  kable() %>% kable_styling()
```

We found that 13 counties had incorrect COVID-19 incidence scores, and the scores seem to be transposed from other counties, such that the overall descriptive statistics were accurate but the correlation coefficients were inaccurate.
This finding implies that subsequent analyses using the COVID-19 Incidence rate will be slightly different and more accurate in this reproduction study than in the original study.

## Bivariate nonparametric correlation analysis

**Unplanned Deviation for Reproduction**: 
The dependent and independent variables in this study do not have normal distributions, as shown in the Shapiro-Wilk test results above.
Therefore, we deviate from the original study to use the Spearman's Rho non-parametric correlation test.

```{r spearmans correlation}
df <- sum(!is.na(acs_covid$dis_pct)) - 2

spearmans_rho <- acs_covid %>%
  select(where(is.numeric)) %>%
  st_drop_geometry() %>%
  cor(method = "spearman", use = "everything") %>%
  as.data.frame() %>%
  select(rho = covid_rate) %>%
  mutate(
    t = abs(rho) / sqrt((1 - rho^2) / (df)),
    p = pt(t, df, lower.tail = FALSE)
  ) %>%
  round(3) %>%
  rownames_to_column("variable") %>%
  filter(variable != "covid_rate")
```

Compare the Spearman's *rho* correlation coefficients to the reproduced Pearson's *r* correlation coefficients.
Differences are calculated as *Spearman's Rho* - *Pearson's R*.

```{r compare-spearmans-correlation}
# calculate number of significance stars at p<0.01 and P<0.05 levels.
spearmans_rho <- mutate(spearmans_rho, rp_rho_stars = as.numeric(as.character(cut(p,
  breaks = c(-0.1, 0.01, 0.05, 1),
  labels = c(2, 1, 0)
))))

correlations <- correlations[, 1:8] %>%
  left_join(select(spearmans_rho, variable, rp_rho = rho, rp_rho_stars), by = "variable")

corrdiff <- select(correlations, starts_with("rp_rho")) -
  select(correlations, rp_r, rp_stars)

correlations <- correlations %>% bind_cols(rename_with(corrdiff, ~ paste0(.x, "_diff")))
rm(corrdiff)

correlations <- correlations %>% mutate(rp_rho_dir_diff = (rp_rho > 0) - (rp_r > 0))

correlations %>%
  select(variable, rp_r, rp_stars, starts_with("rp_rho")) %>%
  kable(col.names = c("Variable", "R", "Stars", "Rho", "Stars", "Rho - R", "Stars", "Direction"),
        align = "c") %>% 
  #column_spec(2:6, width_min = "5em") %>% 
  kable_styling() %>% 
  add_header_above(c(" " = 1, "Pearson's" = 2, "Spearman's" = 2, "Difference" = 3))
```

Three variables change significance levels, with *Native American* and *Other* races gaining significance and *age 18-34* losing significance.
Two correlations change direction, with both *Native American* race (illustrated in scatterplot below) and *Female* households switching from positive correlations to negative correlations.
Instabilities between the parametric and non-parametic correlations arise from variables with very skewed distributions and/or weak correlations at the county level.
Some difference may also be attributable to the 13 counties with data errors in the COVID-19 Incidence Rate.
In such distributions, outlier observations have more weight in the parametric Person's R test than in the non-parametric Spearman's Rho test.

```{r plot-bivariate, fig.width=4, fig.height=4}
plot(acs_covid$native_pct,
  acs_covid$covid_rate,
  xlab = "Percent Native American",
  ylab = "COVID-19 Incidence",
  pch = 16,
  col = rgb(0, 0, 0, 0.05),
  cex.lab = 0.8,
  cex.axis = 0.5,
)
lines(abline(lm(acs_covid$covid_rate ~ acs_covid$native_pct)))

rm(spearmans_rho, pearsons_r, correlations, table1, df)
```

## Kulldorff spatial scan statistic

We use a Kulldorff spatial scan statistic to detect spatial clusters of high COVID-19 incidence (workflow step 6).
The statistic uses a Monte Carlo simulation to calculate statistical significance, and therefore may not produce identical results each time.

The original study uses SaTScan software to implement the Kulldorff spatial scan statistic model.
In SaTScan, models may be specified with many parameters having significant implications for results.
The original manuscript only specifies that Poisson model should be used.
We can also intuit that the model is discrete (locations are stationary and non-random), and spatial only (there is no temporal dimension).
The author-provided SaTScan results `SatScan_results.txt` contains additional parameters which appear to adhere closely to the software's default settings.
These include the maximum cluster size of "50 percent of population at risk", and the "GINI optimized cluster collection" and "no geographical overlap" options for detecting secondary clusters.
The "P-value Cutoff" for significant clusters option did not appear in the v9.6 output, suggesting that the software only allowed the default "no" option for this at the time of the original study.

SaTScan software can also output two versions of geographic data:

-   The `col` cluster polygon shapefile contains a circle for each cluster, where each polygon is a circle defined by the cluster center and radius. The attributes include a variable `REL_RISK` for cluster relative risk
-   The `gis` location point shapefile contains one point for each county in a cluster. The attributes include variables `LOC_RR` for local relative risk and `CLU_RR` for cluster relative risk

The SaTScan software implementation of the Kulldorff spatial scan statistic calculates two relative risk scores for locations:

-   cluster relative risk is the incidence rate of the population within the cluster divided by the incidence rate of the population outside of the cluster. This is calculated as `REL_RISK` in the `col` cluster polygon shapefile and as `CLU_RR` in the `gis` location point shapefile.
-   local relative risk is the incidence rate of population within a location divided by the incidence rate of the population outside of the location. This is calculated as `LOC_RR` in the `gis` location shapefile, and is not calculated in the `col` cluster polygon shapefile.

For the purposes of interpreting the spatial scan statistic, a *location* is a *county centroid* while a *cluster* is a *collection of counties* with high incidence rates, defined in the shape of a circle with a *center* location (a county centroid) and a *radius*.

The original study is not clear about using the cluster geographic data *vs* the location geographic data or the cluster relative risk *vs* local relative risk.
However, The author-provided `SatScan_results.txt` results file indicates a geographic cluster file but no location file, and the author-provided `Aug1GEEdata.csv` data table contains a `REL_RISK` field but no `CLU_RR` field or `LOC_RR` field.
This suggests that in the original study, the `col` polygon cluster shapefile and *cluster* relative risk were used to represent COVID-19 risk and define GEE clusters.

The spatial scan statistic is based on case counts and total population, and is therefore unaffected by errors in the COVID Incidence rate.

**Planned deviation for reproduction**: We opted to use the SpatialEpi package in R, selecting open source software with R integration over SatSCan software, which is free but not open.
The Kulldorff spatial scan statistic model in SpatialEpi also supports a discrete Poisson spatial model, and uses the GINI coefficient to select secondary clusters with no geographical overlap that maximize the difference between locations inside of clusters and locations outside of clusters.
We expected that this set of software options could reproduce identical results compared to SaTScan.

First, calculate the Kulldorff spatial scan statistic using SpatialEpi.
Optionally, skip this code block due to long run times of more than 10 minutes.

```{r SpatialEpi-Kulldorff, eval = FALSE, fig.width=4, fig.height=4}
start_time <- Sys.time()
covid_geo <- covid_table %>%
  select(x, y) %>%
  latlong2grid()
# latlong2grid creates approximate equidistant cylindrical grid
# could probably reproject to epsg 5070 and create table with x and y

# calculate expected cases with one strata
expected.cases <- expected(covid_table$pop, covid_table$cases, 1)

# Kulldorff spatial scan statistic
covid_kulldorff <- kulldorff(
  geo = covid_geo,
  cases = covid_table$cases,
  population = covid_table$pop,
  expected.cases = expected.cases,
  pop.upper.bound = 0.5,
  n.simulations = 999,
  alpha.level = 0.05,
  plot = TRUE
)

print(
  paste(
    "Run time:",
    round(difftime(Sys.time(), start_time, units = "mins"), 2),
    "minutes"
  ),
  quote = FALSE
)
rm(covid_geo, expected.cases, start_time)

# save results in a file appended with the current date
saveRDS(covid_kulldorff,
  file = here("data", "derived", "public", paste0("covid_kulldorff_", Sys.Date(), ".RDS"))
)
```

Load pre-calculated Kulldorff spatial scan results.
Alternatively, skip or modify this code block to use your own version of the SpatialEpi Kulldorff results.

```{r load-Kulldorff}
# load pre-calculated Kulldorff results
# alternatively, modify the file name with an appended date to load a more current set of results
covid_kulldorff <- readRDS(
  here("data", "derived", "public", "covid_kulldorff.RDS")
)
```

Report Kulldorff spatial scan results.

```{r report-Kulldorff}
print("Most likely cluster:", quote = FALSE)
covid_kulldorff$most.likely.cluster
print(
  paste0(
    "Number of Secondary clusters: ",
    length(covid_kulldorff$secondary.clusters)
  ),
  quote = FALSE
)
```

The `SpatialEpi` implementation of Kulldorff spatial scan statistics provides output in the form of hierarchical lists analogous to the text output of SaTScan, but does not output a simple data frame or tabular output analogous to the shapefiles from SaTScan.
Therefore, additional steps are required to append the Kulldorff scan results to the `acs_covid` simple features data frame.
This can be done by assigning unique cluster ID's to each county within a cluster.
Clusters include the county at the center of a cluster and all of the other counties within the cluster radius.
Therefore, we use the FIPS code of the county at the center of each cluster as the unique cluster ID.

```{r assign-cluster-IDs, message = FALSE}
# list of primary cluster locations (counties)
cluster_locations <- covid_kulldorff$most.likely.cluster$location.IDs.included

# create data frame of clusters and
# calculate the clusterID as the first (center) county FIPS code
clusters <- covid_table[cluster_locations, "fips"] %>%
  mutate(clusterID = covid_table[[cluster_locations[1], "fips"]],
         likelihood = covid_kulldorff$most.likely.cluster$log.likelihood.ratio)

# Get a list of secondary clusters
secondary <- covid_kulldorff$secondary.clusters

# similarly add counties in each secondary cluster to the list of clusters
for (i in secondary) {
  cluster_locations <- i$location.IDs.included
  new_clusters <- covid_table[cluster_locations, "fips"] %>%
    mutate(clusterID = covid_table[[cluster_locations[1], "fips"]],
           likelihood = i$log.likelihood.ratio) 
  clusters <- clusters %>% rbind(new_clusters)
}

rm(cluster_locations, secondary, i, new_clusters)
```

### Map Kulldorff clusters

**Unplanned deviation for reproduction**: 
The original study does not include visualizations of the spatial structure and distribution of COVID-19 clusters.

First, we must join the Kulldorff spatial scan cluster IDs to the acs_covid simple features dataframe.
Although this was planned in workflow step 9, the order of operations between steps 9 and steps 7 and 8 is not important.

Next, calculate a new field `isCluster` to identify counties in COVID-19 clusters.
Additionally, distinguish between counties defining the center of a cluster from counties constituting other parts of a cluster by comparing the cluster ID (equivalent to the center county's fips code) to the county fips code.

```{r join-clusterID-to-acs_covid}
acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "y")] %>%
  left_join(clusters, by = "fips") %>%
  mutate(isCluster = case_when(
    clusterID == fips ~ "center of cluster",
    !is.na(clusterID) ~ "other part of cluster",
    .default = NA
  ))
```

**Planned deviation for reproduction**:
Map the `SpatialEpi` cluster results.

```{r map-clusters}
tm_spatialepi_clusters <-
  tm_shape(state) +
    tm_fill("gray98") +
  tm_shape(acs_covid) +
  tm_polygons(col = "isCluster", 
          palette = "-Oranges", 
          popup.vars = c("fips", "clusterID"), 
          colorNA = NULL,
          title = "SpatialEpi Kulldorff COVID-19 Clusters",
          border.col = "white",
          lwd = 0.2,
          border.alpha = 0.2) +
  tm_shape(state) +
    tm_borders("grey", lwd = 0.5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_clusters
```

**Unplanned deviation for reproduction**: The `SpatialEpi` implementation of Kulldorff spatial scan statistics does not calculate local relative risk or cluster relative risk.
Therefore, the next step is to calculate local and cluster relative risk (workflow step 7).

```{r relative-risk}
total_pop <- sum(acs_covid$pop)
total_cases <- sum(acs_covid$cases)

acs_covid <- acs_covid %>%
  group_by(clusterID) %>%
  mutate(
    rr_cluster = ifelse(is.na(clusterID), NA,
      (sum(cases) / sum(pop)) / ((total_cases - sum(cases)) / (total_pop - sum(pop)))
    )
  ) %>%
  ungroup() %>% 
  mutate(
    rr_loc = (cases / pop) / ((total_cases - cases) / (total_pop - pop))
  )

rm(total_pop, total_cases)
```

Classify relative risk on a scale from 1 to 6 (workflow step 8).
Counties falling outside of any cluster are assigned a score of 1.

```{r classify-relative-risk}
# class breaks
breaks <- c(-Inf, 1, 2, 3, 4, 5, Inf)

acs_covid <- acs_covid %>%
  mutate(
    cluster_class = ifelse(is.na(clusterID), 1, cut(rr_cluster, breaks, labels = FALSE)),
    loc_class = cut(rr_loc, breaks, labels = FALSE)
  )

acs_covid %>% 
  st_drop_geometry() %>% 
  select(clusterID, rr_cluster, cluster_class, rr_loc, loc_class) %>% 
  head()
```

### Map relative risk scores

**Unplanned deviation for reproduction**: 
It would be helpful to visualize the spatial distributions of local relative risk classes and
Kulldorff cluster relative risk classes in advance of using these classes to control for spatial heterogeneity in GEE models.

First, map the spatial distribution of local relative risk score classifications.

```{r map local relative risk score}
# count the frequency of counties in each class and create labels
class_freq <- acs_covid %>% st_drop_geometry() %>% count(loc_class)
class_freq$qual <- ifelse(class_freq$n > 1, " counties", " county")
class_freq[1, ]$qual <- paste(class_freq[1, ]$qual, "at low risk")
class_freq[nrow(class_freq), ]$qual <- paste(class_freq[nrow(class_freq), ]$qual, "at high risk")
class_freq$label <- paste0(class_freq$loc_class, 
                           " (", 
                           class_freq$n, 
                           class_freq$qual,
                           ")")

# Map Local Relative Risk scores
tm_spaitalepi_local_risk_class <- tm_shape(acs_covid) +
  tm_polygons("loc_class",
    title = "Local Relative Risk Class",
    border.col = "white",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges",
    style = "cat",
    labels = class_freq$label
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

rm(class_freq)

tm_spaitalepi_local_risk_class
```

Next, map the cluster relative risk scores for comparison.
Note that following the original study classification methodology, counties outside of clusters are assigned the lowest risk class of `1`.

```{r map-cluster-relative-risk-classes}
# count the frequency of counties in each class and create labels
class_freq <- acs_covid %>% st_drop_geometry() %>% count(cluster_class)
class_freq$qual <- ifelse(class_freq$n > 1, " counties", " county")
class_freq[1, ]$qual <- paste(class_freq[1, ]$qual, "at low risk")
class_freq[nrow(class_freq), ]$qual <- paste(class_freq[nrow(class_freq), ]$qual, "at high risk")
class_freq$label <- paste0(class_freq$cluster_class, 
                           " (", 
                           class_freq$n, 
                           class_freq$qual,
                           ")")

# map cluster relative risk scores
tm_spaitalepi_cluster_risk_class <- tm_shape(acs_covid) +
  tm_polygons("cluster_class",
    title = "Cluster Relative Risk Class",
    border.col = "white",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges",
    style = "cat",
    labels = class_freq$label
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

rm(class_freq)

tm_spaitalepi_cluster_risk_class
tm_spaitalepi_local_risk_class
```

Comparing the cluster and local relative risk classifications for regions like the Southeast, it is apparent that some areas of high risk are represented with large clusters that have an averaging effect on the cluster-based relative risk score. 
This is effect is more pronounced for clusters with low compactness (e.g. the Southeast cluster stretched over the "black belt" region from Louisiana and Arkansas to Georgia) than clusters with higher compactness (e.g. New York City) because the circular shape of clusters includes more low-risk counties.

### Compare clusters

The original study did not directly report any results from the Kulldorff spatial scan statistic.
However, the Kulldorff cluster relative risk scores were combined with states to create clusters for GEE models, hereafter called "GEE clusters".
The original study reported `102` unique GEE clusters having a range of `1` to `245` counties in each cluster.

In order to compare results, we first create cluster IDs as combinations of the relative risk class and the state ID.
Then, we find the number of unique clusters and frequency counties per cluster in our reproduction study for comparison to the original study.

```{r make-gee-clusters}
# calculate clusters
acs_covid <- acs_covid %>% mutate(
  clusID = as.integer(statefp) * 10 + cluster_class
)

# summarize clustering results
cluster_summary <- acs_covid %>%
  filter(cases > 0) %>%
  st_drop_geometry() %>%
  count(clusID)
cat(
  length(cluster_summary$n),
  "unique clusters based on spatialEpi CLUSTER relative risk\n"
)
summary(cluster_summary$n)
rm(cluster_summary)
```

We failed to reproduce the same configuration of GEE clusters as the original study, finding 9 more clusters than the original study and a much smaller maximum cluster of 159 counties compared to 245 counties.

### Reproduce Kulldorff spatial scan statistic in SaTScan

**Unplanned deviation for reproduction**:
Upon failing to reproduce an identical number of GEE clusters using SpatialEpi in R, we reproduced the procedure in the free but not open SaTScan software, using the current software version 10.1.
The input data files (`case`, `Coordinates.geo`, and `Population.pop`), and output data files (`sat_scan_rpr.txt`, `sat_scan_rpr.col.shp`, and `sat_scan_rpr.gis.shp`) are found in the `data/derived/public/satscan` directory.
The `sat_scan_rpr.txt` file reports the model parameters used in addition to results.

Although it is not ideal to intercede with this unplanned deviation at this step, is the first step in the methodology following the Kulldorff spatial scan statistic with a result reported in the original publication.

First, load and verify whether our SaTScan reproduction data compares to the author-provided SaTScan data.

```{r load-satscan-col}
# load author-provided data
author_col <- read.dbf(here("data", "raw", "public", "chakraborty", "SatScan_output.dbf")) %>% 
  select(LOC_ID, or_rel_risk = REL_RISK)

# load SaTScan reproduced data
satscan_rpr_col <- read_sf(here("data", "derived", "public", "satscan", "sat_scan_rpr.col.shp"))

# how many observations?
cat(
  nrow(satscan_rpr_col),
  " reproduced relative risk observations\n",
  nrow(author_col),
  " author-provided relative risk observations\n",
  sep = ""
)

# join and compare how many observations are identical?
cat(
  satscan_rpr_col %>% 
  full_join(author_col, by = "LOC_ID") %>% 
  filter(REL_RISK == or_rel_risk & REL_RISK > 0) %>% 
  nrow(),
  "reproduced relative risk values match the original author's relative risk values"
  )

rm(author_col)
```

Our SaTScan results exactly reproduced the author-provided SaTScan results data.

#### Map SaTScan spatial clusters

Join the SaTScan results to `acs_covid` for mapping and analysis.

```{r join-satscan-to-acs-covid}
# check if there are any duplicated counties
cat("Joining", 
    length(satscan_rpr_col$LOC_ID), 
    "records with",
    length(unique(satscan_rpr_col$LOC_ID)),
    "unique LOC_ID county values")

# select important non-geographic columns
satscan_rpr_col_t <- satscan_rpr_col %>% 
  st_drop_geometry() %>% 
  select(fips = LOC_ID, GINI_CLUST, REL_RISK)

# join
acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "loc_class")] %>% 
  left_join(satscan_rpr_col_t, by = "fips")

rm(satscan_rpr_col_t)
```

**Unplanned deviation for reproduction**:
Visualize the spatial distribution of the author-provided Kulldorff COVID-19 Clusters.

```{r map--author-clusters}
# count frequencies of each cluster type
clus_counts <- satscan_rpr_col %>% 
  st_drop_geometry() %>% 
  group_by(GINI_CLUST) %>% 
  summarize(n = n())

# create labels including frequencies in brackets
clus_labels <- c(paste0("Hierarchical (", clus_counts[1,2], ")"),
            paste0("GINI Optimized (", clus_counts[2,2], ")"))

# for clusters with only one county, erase the number of counties
satscan_rpr_col[which(satscan_rpr_col$NUMBER_LOC < 3), ]$NUMBER_LOC <- NA

gini_circle <- satscan_rpr_col %>% filter(GINI_CLUST == 'T')
hier_circle <- satscan_rpr_col %>% filter(GINI_CLUST == 'F')

tm_author_clusters <-
  tm_shape(state) +
    tm_fill("gray98") +
  tm_shape(acs_covid) +
  tm_polygons(col = "GINI_CLUST",
              labels = clus_labels,
              border.col = "white",
              lwd = 0.5,
              palette = c("tomato", "thistle3"), 
              popup.vars = c("fips", "clusterID"), 
              colorNA = NULL,
              title = "SaTScan Kulldorff COVID-19 Clusters\nCluster Centers") +
  tm_shape(state) +
    tm_borders("grey", lwd = 0.5) +
  tm_shape(gini_circle) +
    tm_borders(col = "thistle4") +
    tm_text("NUMBER_LOC", size = 0.5) +
  tm_shape(hier_circle) +
    tm_borders(col = "tomato") +
    tm_text("NUMBER_LOC", size = 0.5, ymod = 0.4) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  ) +
  tm_add_legend('symbol', 
              	col = NA,
              	border.col = c("tomato", "thistle4"),
              	size = 0.7,
              	labels = clus_labels,
              	title="Cluster Extents")

tm_author_clusters

rm(gini_circle, hier_circle, clus_counts, clus_labels)
```

In the map above, clusters containing only one county have no visible circle.
Clusters containing two counties are encircled, but have no label.
Clusters containing three or more counties are encircled and labelled with the number of counties.

Note that this version of data only includes the 96 counties defining cluster centers, visualized with fill colors above.
The data excludes all of the non-center counties in clusters with more than one county.
The extent of these larger clusters is visualized by unfilled circles defined by cluster radii.

Additionally, the SaTScan software confusingly merges two sets of clusters in the results when the user uses the (default) option for GINI-optimized clusters.
One set of results is a hierarchical non-overlapping set of clusters.
These clusters are noted with `GINI_CLUST = F` in the results.
The second set of results is a set of hierarchical non-overlapping clusters designed to maximize the GINI coefficient of inequality between counties within clusters and counties outside of clusters.
These clusters are noted with `GINI_CLUST = T` in the results.

Merged together as they are, the two sets of secondary clusters overlap one another geographically, causing ambiguity in terms of which cluster-based relative risk score should be used at each location.

**Unplanned deviation for reproduction**: Can we also use these reproduced SaTScan results to exactly reproduce the author-reported frequency of original GEE classes and maximum counties per class?
If the results match, it will confirm that the problems identified above have propagated through the original study analysis.

```{r reproduce-gee-clusters}
acs_covid <- acs_covid %>%
  mutate(
    ss_cluster_class = ifelse(is.na(REL_RISK), 1, cut(REL_RISK, breaks, labels = FALSE)),
    ss_clusID = as.integer(statefp) * 10 + ss_cluster_class
  )

cluster_summary <- acs_covid %>%
  filter(cases > 0) %>%
  st_drop_geometry() %>%
  count(ss_clusID)
cat(
  length(cluster_summary$n),
  "unique clusters based on spatialEpi CLUSTER relative risk\n"
)
summary(cluster_summary$n)
```

Using SaTScan Kulldorff clusters, we have exactly reproduced the author-reported frequency of original GEE classes and maximum counties per class.
We have confirmed that the original study used the *cluster relative risk* of the *center county* of each cluster, including both the *hierarchical* and *GINI-optimized* sets of clusters. 

#### Compare SaTScan clusters to SpatialEpi clusters

**Unplanned Deviation for Reanalysis:**
At this point it is clear that the best decision will be to shift from a *reproduction* study to a *reanalysis* study, intentionally altering methodological decisions to achieve a more valid outcome.
We prefer to include *all counties* contained in each cluster, and to use only *one set of non-overlapping clusters*, as produced by the `SpatialEpi` algorithm.

Given the shifting goal, how sensitive is this study to the choice of computational environment for the Kulldorff scan statistics?
To answer this question, we must load the local SaTSCan results inclusive of all counties within clusters, filter the results to focus on the standard hierarchical set of clusters, and compare the spatial distributions of the SaTScan and SpatialEpi results.

```{r join-satscan-clusters-all-counties, message = F}
# load local SaTScan reproduced data
satscan_rpr_gis_t <- read_sf(
  here("data", "derived", "public", "satscan", "sat_scan_rpr.gis.shp")
) %>%
  st_drop_geometry() %>%
  select(fips = LOC_ID, CLU_RR, GINI_CLUST)

# check if there are any duplicated counties
cat("Joining", 
    length(satscan_rpr_gis_t$fips), 
    "records with",
    length(unique(satscan_rpr_gis_t$fips)),
    "unique county values")

satscan_rpr_gini <- satscan_rpr_gis_t %>% filter(GINI_CLUST == "T") %>% select(fips, gini_rr = CLU_RR)
satscan_rpr_hier <- satscan_rpr_gis_t %>% filter(GINI_CLUST == "F") %>% select(fips, hier_rr = CLU_RR)

acs_covid <- acs_covid[, 1:which(colnames(acs_covid) == "ss_clusID")] %>%
  left_join(satscan_rpr_gini, by = "fips") %>% 
  left_join(satscan_rpr_hier, by = "fips")

rm(satscan_rpr_gis_t, satscan_rpr_gini, satscan_rpr_hier)
```
Compare the SaTScan Hierarchical clusters to the SpatialEpi clusters.

```{r hierarchical-cluster-comparison-map, message = F}
hier_clusters <- acs_covid %>%
  mutate(xcluster = case_when(
    !is.na(hier_rr) & is.na(isCluster) ~ "SaTScan Hierarchical only",
    !is.na(hier_rr) & !is.na(isCluster) ~ "Both SaTScan and SpatialEpi",
    is.na(hier_rr) & !is.na(isCluster) ~ "SpatialEpi only",
    .default = NA
  )) %>%
  filter(!is.na(xcluster)) %>%
  group_by(xcluster) %>%
  mutate(xn = n()) %>%
  ungroup() %>%
  mutate(xcluster = paste0(xcluster, " (", xn, " counties)"))

tm_spatialepi_hier <-
  tm_shape(state) +
  tm_fill("gray98") +
  tm_shape(hier_clusters) +
  tm_polygons(
    col = "xcluster",
    palette = c("wheat", "tomato", "thistle3"),
    colorNA = NULL,
    title = "SaTScan Hierarchical and SpatialEpi Clusters",
    border.col = "white",
    lwd = 0.2,
    border.alpha = 0.3
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = 0.5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_hier

rm(hier_clusters)
```

The two methods only agree on the definition of the largest clusters in distant regions.
Thereafter, SpatialEpi detects many secondary clusters in the vicinity of the largest ones, while SaTScan detects seven isolated and low-probability counties.

Compare the SaTScan GINI Optimized clusters to the SpatialEpi clusters.

```{r gini-cluster-comparison-map, message = F}
gini_clusters <- acs_covid %>%
  mutate(xcluster = case_when(
    !is.na(gini_rr) & is.na(isCluster) ~ "SaTScan GINI optimized only",
    !is.na(gini_rr) & !is.na(isCluster) ~ "Both SaTScan and SpatialEpi",
    is.na(gini_rr) & !is.na(isCluster) ~ "SpatialEpi only",
    .default = NA
  )) %>%
  filter(!is.na(xcluster)) %>%
  group_by(xcluster) %>%
  mutate(xn = n()) %>%
  ungroup() %>%
  mutate(xcluster = paste0(xcluster, " (", xn, " counties)"))

tm_spatialepi_gini <-
  tm_shape(state) +
  tm_fill("gray98") +
  tm_shape(gini_clusters) +
  tm_polygons(
    col = "xcluster",
    palette = c("wheat", "tomato", "thistle3"),
    colorNA = NULL,
    title = "SaTScan GINI Optimized and SpatialEpi Clusters",
    border.col = "white",
    lwd = 0.2,
    border.alpha = 0.3
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = 0.5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_gini

rm(gini_clusters)
```

There is more agreement overall between SpatialEpi and SaTScan GINI Optimized clusters.
The two algorithms agree the most for smaller and less significant clusters above the 95% confidence threshold. 
Because the SaTScan clusters are more limited in size, SaTScan detects several smaller clusters with gaps in place of the largest SpatialEpi clusters.

Keeping in mind that the final analysis uses a classification of cluster relative risk for GEE models, are there important differences between the two results with regard to classification of risk?
We can check by calculating cluster relative risk classes based on the SaTScan GINI clusters, and cross-tabulating with the SpatialEpi risk classes.

```{r compare-spatialepi-satscan}
acs_covid <- acs_covid %>%
  mutate(
    gini_class = ifelse(is.na(gini_rr), 1, cut(gini_rr, breaks, labels = FALSE)),
    gini_clusID = as.integer(statefp) * 10 + gini_class 
  )

table(acs_covid$cluster_class, acs_covid$gini_class) %>%
  kable(row.names = TRUE, caption = "COVID-19 Risk Class by County", align = "c") %>%
  column_spec(2:7, width = "3em") %>%
  column_spec(1, bold = TRUE) %>%
  add_header_above(c("SpatialEpi" = 1, "SatScan" = 6)) %>% 
  kable_styling(full_width = FALSE, row_label_position = "c")
```

Indeed, SpatialEpi has identified more than 300 counties with above normal risk that were not identified by SaTScan.
Meanwhile, SaTScan identified 78 counties with above normal risk that were not identified by SpatialEpi.

The maps and crosstabulation above indicate that there are important differences between the SaTScan and SpatialEpi computational environments for calculating secondary clusters.

We summarize our understanding of the computational differences for default settings below, based on close examination of our software outputs, technical documentation for SaTScan, and the documentation and code repository for SpatialEpi.

|                     | SaTScan Hierarchical Clusters |       SaTScan GINI Clusters        | SpatialEpi Clusters |
|:----------------:|:----------------:|:----------------:|:----------------:|
| possible shapes | circle (default) or ellipse | circle (default) or ellipse  | circle |
| possible cluster centers | locations with rates > normal | locations with rates > normal | all locations |
| maximum cluster size |         50% of cases          | varies, not exceeding 50% of cases |  50% of population  |
|     maximum *p* of cluster  |   1.00              |                1.00                |        0.05         |
| distance | spherical great circle | spherical great circle | spherical equidistant cylindrical projection |

To further interrogate the differences in sets of secondary clusters, we must understand that theoretically each location (county), may be the center of many different circular clusters defined by different radii, starting with a radius of 0 and the one county at the center, and expanding until the maximum cluster size is reached. 

**SaTScan Hierarchical Clusters**

- Select locations (counties) with above-normal COVID incidence rates
- For each location, find log-likelihood of all possible cluster sizes (from minimum of 2 cases to maximum of 50% of cases) with *p* < 1
- For each location, select the cluster with the maximum log-likelihood, resulting in one possible cluster for each location with above-normal COVID incidence rates
- Sort the remaining clusters by log-likelihood from greatest to least
- Select the most likely cluster
- Select secondary clusters by iterating over the remaining clusters, adding new clusters to the set of secondary clusters if they do not geographically overlap any of the clusters already identified as most likely or secondary (pg 68).

**SaTScan GINI-Optimized Clusters**

- Follow the same procedure as SaTScan Hierarchical clusters, but iterate the procedure with different maximum cluster sizes. By default the cluster sizes include 1, 2, 3, 4, 5, 6, 8, 10, 12, 15, 20, 25, 30, 35, 40, 45, and 50 percent of cases. With the default setting, the result is 17 different sets of clusters.
- For each set of clusters, calculate the GINI coefficient of the COVID-19 incidence inside the clusters vs outside the clusters.
- Select the set of clusters with the highest GINI coefficient (i.e. the most difference between COVID-19 incidence inside the clusters vs outside the clusters).

**SpatialEpi Clusters**

- For all locations, calculate the log likelihood of all the possible clusters below the maximum cluster size (50% of population) 
- Select the clusters with *p* < 0.05
- Sort the remaining clusters by log-likelihood from greatest to least (line 186)
- Select the most likely cluster
- Select secondary clusters by iterating over the remaining clusters, adding new clusters to the set of secondary clusters if they do not geographically overlap any of the clusters already identified as most likely or secondary (line 199).

The differences between these three approaches have very significant impacts on the results (see the differences in results in the **two maps** above) and it is impossible to control for all of the differences with the available parameters.
Most fundamentally, SaTScan develops sets of secondary clusters from a universe of just one most likely cluster per location with no default limitation its statistical significance, whereas SpatialEpi may consider multiple possible cluster sizes for each location with a default limitation of maximum 0.05 *p* for each cluster.
These fundamental differences are evident in the spatial distribution of clusters.
For example, New York City is the most likely cluster in all analyses.
For counties near New York, the radius of the most likely cluster is large and geographically overlaps New York City.
Therefore, if only the most significant cluster radius is considered as a possible secondary cluster for counties near New York City, all such clusters are disqualified by their geographical overlap. 
This is what happens in the SaTScan Hierarchical Clusters model, for which the next nearest clusters are in Ohio and Virginia.
In the SaTScan GINI-optimized model, the maximum cluster size is apparently smaller, such that the most likely cluster in New York City is also smaller. 
This change allows for two other non-overlapping secondary clusters in Rhode Island and New Jersey.
In contrast, the SpatialEpi algorithm still considers a variety of possible cluster sizes for each county, allowing for detection of smaller clusters adjacent to more significant ones.

Of course, the *relative risk* score of each cluster is contingent on the cluster size, so each difference in geographic configuration of clusters also impacts the cluster risk classification of individual locations. 
The most stable results are for the most likely clusters in distinct regions (New York City, Southeast U.S., Southern California & Nevada), while the most variability appears for secondary clusters close enough for their most likely radius to overlap the more likely clusters. 
The circular shape could be considered a major limitation of Kulldorff cluster detection, for which the SaTScan methodology enhances the limitation by constraining the possibility of nearby clusters while the SpatialEpi methodology can detect smaller adjacent secondary clusters.

The high significance threshold in the default SaTScan analysis allows the inclusion of many small clusters with low likelihoods, adding noise to the results.
This could be controlled by overriding the maximum *p* value parameter.
Combining all of the default parameters, SaTSCan includes small clusters of relatively low-risk counties in the Midwest, but excludes relatively high-risk counties adjacent to the major clusters of New York, the Southeast, and Southern California/Nevada. 
This problem does not exist in the SpatialEpi implementation, and the SpatialEpi parameter *alpha level* parameter cannot be practically increased to `1` to match the SatSCan default.
This is because SpatialEpi does not filter counties by those with local relative risk greater than 1---therefore an *alpha value* of `1` results in *all* counties being included as clusters.

In sum, there are three construct validity issues with the original study COVID-19 high-risk clusters as implemented in SaTScan.

1. Two sets of overlapping secondary clusters are included in the SaTScan output: hierarchical clusters and clusters optimized by GINI coefficient.
2. Only the 96 counties at the center of a cluster are considered in the risk classification.
3. The geographic patterns and cluster relative risk scores of secondary clusters are limited to circles or ellipses and are apparently sensitive to both the geographic shape and situation of high-risk clusters and to subjective decisions in parameters and algorithms.

## Preprocess data for GEE modelling

**Unplanned deviation for reanalysis**: 
Based on the three observations above, we think that it would be more valid to choose one set of secondary clusters based on a single method rather than combining a set of hierarchical clusters with a set of GINI optimized clusters.
We also think that it would be more valid to include risk levels for all counties within a cluster (i.e. all counties within any of the circles above), rather than only the county at the center of a cluster.
Finally, we think it would be more valid to treat clusters as a single category rather than five tiers of above-normal risk.

To complete the reproduction/reanalysis study, we will therefore calculate and compare multiple versions of the GEE models:

1. Original study results
2. Original study data in geepack
3. SpatialEpi cluster classification in geepack
4. SpatialEpi binary clusters in geepack



### Unique GEE cluster IDs

First, calculate GEE cluster IDs.

We have already calculated:
- `clusID` based on our SpatialEpi clusters 
- `ss_clusID` based on our SaTScan cluster centers, and shown to be identical to the original author's data
- `gini_clusID` based on our SaTScan GINI-optimized clusters

However, if we want to test the original study data in geepack, we need to pre-calculate the unique GEE cluster ID as `or_clusID`
This step is implied in the "check number of unique clusters and number of counties per cluster" step of the workflow diagram.

### Filter and standardize data

Second, filter the data for non-zero COVID-19 rates and z-score standardize the independent variables.
This accomplishes step 10 of the workflow diagram.

**Unplanned deviation for reproduction:**
We assumed that we should filtered for COVID rates > 0 first and then calculate z-scores, however after comparing data in the next code block, we realized that the original study had first calculated z-scores and then filtered for COVID rates > 0.

```{r filter-standardize}
gee_data <- acs_covid %>%
  mutate(
    z_white_pct = scale(white_pct),
    z_black_pct = scale(black_pct),
    z_native_pct = scale(native_pct),
    z_asian_pct = scale(asian_pct),
    z_other_pct = scale(other_pct),
    z_non_hisp_white_pct = scale(non_hisp_white_pct),
    z_hisp_pct = scale(hisp_pct),
    z_non_hisp_non_white_pct = scale(non_hisp_non_white_pct),
    z_bpov_pct = scale(bpov_pct),
    z_apov_pct = scale(apov_pct),
    z_pct_5_17 = scale(pct_5_17),
    z_pct_18_34 = scale(pct_18_34),
    z_pct_35_64 = scale(pct_35_64),
    z_pct_65_74 = scale(pct_65_74),
    z_pct_75 = scale(pct_75),
    z_male_pct = scale(male_pct),
    z_female_pct = scale(female_pct)
  ) %>%  
  filter(covid_rate > 0) #moved filtering to after z-score calculation
```

Compare independent variables for GEE models.

```{r compare-indp-vars}

gee_diff <- 
  (gee_data %>% 
    st_drop_geometry() %>%  
    arrange(as.integer(fips)) %>%
    select(starts_with("z_"))  -
  original_gee %>% 
    filter(Cases > 0) %>% 
    arrange(COUNTY_FIPS) %>% 
    select(starts_with("ZPD"))) %>% 
  round(digits = 3)

cat("Summary of difference between reproduction independent variables and original independent variables")
cat("\n")
cat("Mean:\n")
colMeans(gee_diff) %>% round(digits = 3)
cat("\nStandard deviation:\n")
apply(gee_diff, 2, sd) %>% round(digits = 3)

```

There are no major differences between the independent variables.

#### Save final derived data

Optionally, you may save the preprocessed data to `data/raw/public/gee_data.gpkg`

```{r save preprocessed COVID cluster data, eval = FALSE}
write_sf(gee_data, here("data", "derived", "public", "gee_data.gpkg"))
# add saving acs_covid data
```

Optionally, you may load the preprocessed data from `data/raw/public/gee_data.gpkg`

```{r load preprocessed COVID cluster data, eval = FALSE}
gee_data <- read_sf(here("data", "derived", "public", "gee_data.gpkg"))
```

## GEE models

This accomplishes the step 11 of the workflow diagram

Generalized Estimating Equation parameters:

"The **'exchangeable' correlation matrix** was selected for the results reported here, since this specification yielded the best statistical fit based on the QIC (quasi- likelihood under the independence) model criterion." (Chakraborty 2021, Methods paragraph 5)

"The **gamma distribution** with **logarithmic link function** was chosen for all GEEs since this model specification provided the lowest QIC value." (Chakraborty 2021, Methods paragraph 5)

Useful Reference: <https://data.library.virginia.edu/getting-started-with-generalized-estimating-equations/>

```{r load-table2}
table2 <- read.csv(here("data", "raw", "public", "chakraborty", "table2.csv"))
table2 <- table2 %>% arrange(row_i_first)
table2[, 3:ncol(table2)] %>% kable() %>% kable_styling()
```

### GEE Function

Define a function for calculating and summarizing five GEE models

```{r gee-functions}
onegee <- function(gee_data, dep_var, id) {

  # sort data frame by clustering variable, a requirement of GEE modeling
  gee_data <- gee_data %>% arrange({{ id }})

  # create list of models and their independent variables
  model_names <- c(
    "race",
    "ethnicity",
    "poverty status",
    "age",
    "biological sex"
  )
  
  ind_vars <- c(
    "z_white_pct + z_black_pct + z_native_pct + z_asian_pct + z_other_pct",
    "z_non_hisp_white_pct + z_hisp_pct + z_non_hisp_non_white_pct",
    "z_bpov_pct + z_apov_pct",
    "z_pct_5_17 + z_pct_18_34 + z_pct_35_64 + z_pct_65_74 + z_pct_75",
    "z_male_pct + z_female_pct"
  )
  
  gee_models <- data.frame(model_names, ind_vars)
  
  # empty data frame for storing model outputs
  coefficients <- data.frame()
  qics <- data.frame(model_names, qic = c(1:5))

  # run each model and save outputs
  for(i in 1:nrow(gee_models)){

    # run model
    gee_model <- geeglm(
      formula = as.formula(paste(dep_var, "~", gee_models[i, "ind_vars"])),
      data = gee_data,
      id = {{ id }}, # cluster IDs
      family = Gamma(link = "log"),
      corstr = "exchangeable"
    )

    # tidy and save variable coefficients, margins of error, significance...
    gee_table <- tidy(gee_model, conf.int = TRUE)
    gee_table[1, 1] <- paste(gee_models[i, 1], "model intercept")
    coefficients <- coefficients %>% rbind(gee_table)

    # QIC: quasi-likelihood under the independence model information criterion
    QIC(gee_model)
    qics[i, 2] <- QIC(gee_model)[1]
  }
  
  coefficients$stars <- as.numeric(
    as.character(
      cut(coefficients$p.value,
        breaks = c(-0.1, 0.01, 0.05, 1),
        labels = c(2, 1, 0)
      )
    )
  )
  
  # reorder columns to match table2 in publication
  coefficients <- coefficients %>% select(1:3, 6:7, 4, 8, 5)
  
  # combine coefficient results and QIC results into a list
  return_data <- list(
    "coefficients" = coefficients,
    "QICs" = qics)
  
  return(return_data)
}
```

Test the gee function

```{r fun-test}
racemodel <- onegee(gee_data, 
                    dep_var = "covid_rate",
                    id = id)
racemodel$coefficients %>% kable() %>% kable_styling()
```



```{r preprocess original gee data}
original_processed <- original_gee %>%
  filter(Incidence > 0) %>%
  mutate(id = as.integer(COUNTY_FIPS) * 10 + RISK_BIN) %>%
  arrange(id)
```

```{r gee model with author provided data}
# Re-run original author's data from original_gee



```

### Compare GEE results

```{r load-table2}

```


```{r join-gee-results}

```


```{r save-figures, eval = F}
# save figures as image files
# obviously this could be made into a for loop
tmap_save(tm_covid_rates, here("results", "figures", "covid_rates.png"))
tmap_save(tm_disability_rates, here("results", "figures", "disability_rates.png"))
tmap_save(tm_spatialepi_satscan, here("results", "figures", "tm_spatialepi_satscan.png"))
tmap_save(tm_spatialepi_clusters, here("results", "figures", "tm_spatialepi_clusters.png"))
```
